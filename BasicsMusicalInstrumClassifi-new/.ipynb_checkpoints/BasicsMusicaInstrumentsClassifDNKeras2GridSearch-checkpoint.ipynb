{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Very Basics of Musical Instruments Classification using Machine Learning\n",
    "## MFCC, Deep Learning (Gentle introduction using Keras), Sequential Model, Grid Search\n",
    "\n",
    "<br>\n",
    "\n",
    "<p align=\"left\">\n",
    "<img src=\"./img/businesscard.jpg\" width=\"300px\" alt=\"Business Card\" align=\"left\" >\n",
    "</p>\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Oiq428Q4J1s\" frameborder=\"0\" \n",
       "allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\"></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Oiq428Q4J1s\" frameborder=\"0\" \n",
    "allow=\"accelerometer; encrypted-media; gyroscope; picture-in-picture\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "#General\n",
    "import numpy as np\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# System\n",
    "import os, fnmatch\n",
    "\n",
    "# Visualization\n",
    "import seaborn #visualization library, must be imported before all other plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import HTML, display, Image\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Deep Learning\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import History\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# Random Seed\n",
    "import tensorflow\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tensorflow.random.set_seed(2)\n",
    "\n",
    "# Audio\n",
    "import librosa.display, librosa\n",
    "\n",
    "# Configurations\n",
    "path='./audio/london_phill_dataset_multi/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Display a Website\n",
    "def show_web(url):\n",
    "    html_code='<center><iframe src=\"%s\" width=\"800\" height=\"600\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading...</iframe></center>' \\\n",
    "\t\t% (url)\n",
    "    display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 600 audio files in ./audio/london_phill_dataset_multi/\n"
     ]
    }
   ],
   "source": [
    "# Get files in data path\n",
    "\n",
    "files = []\n",
    "for root, dirnames, filenames in os.walk(path):\n",
    "    for filename in fnmatch.filter(filenames, '*.mp3'):\n",
    "        files.append(os.path.join(root, filename))\n",
    "\n",
    "print(\"found %d audio files in %s\"%(len(files),path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"inst_labels.pl\"\n",
    "# Load labels\n",
    "with open(filename, \"rb\") as f:\n",
    "    labels = pickle.load( open( filename, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 classes: cello, flute, oboe, sax, trumpet, viola\n"
     ]
    }
   ],
   "source": [
    "# Encode Labels\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(labels)\n",
    "print(len(labelencoder.classes_), \"classes:\", \", \".join(list(labelencoder.classes_)))\n",
    "classes_num = labelencoder.transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# Signal Processing Parameters\n",
    "fs = 44100         # Sampling Frequency\n",
    "n_fft = 2048       # length of the FFT window\n",
    "hop_length = 512   # Number of samples between successive frames\n",
    "n_mels = 128       # Number of Mel bands\n",
    "n_mfcc = 13        # Number of MFCCs\n",
    "\n",
    "# Machine Learning Parameters\n",
    "testset_size = 0.25 #Percentage of data for Testing\n",
    "n_neighbors=1       # Number of neighbors for kNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save / Load Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"mfcc_feature_vectors.pl\"\n",
    "# Load mfcc features from saved file\n",
    "with open(filename, \"rb\") as f:\n",
    "    scaled_feature_vectors = pickle.load( open( filename, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Train and Test Set\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=testset_size, random_state=0)\n",
    "splits = splitter.split(scaled_feature_vectors, classes_num)\n",
    "for train_index, test_index in splits:\n",
    "    train_set = scaled_feature_vectors[train_index]\n",
    "    test_set = scaled_feature_vectors[test_index]\n",
    "    train_classes = classes_num[train_index]\n",
    "    test_classes = classes_num[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape: (450, 13)\n",
      "test_set shape: (150, 13)\n",
      "train_classes shape: (450,)\n",
      "test_classes shape: (150,)\n"
     ]
    }
   ],
   "source": [
    "# Check Set Shapes\n",
    "print(\"train_set shape:\",train_set.shape)\n",
    "print(\"test_set shape:\",test_set.shape)\n",
    "print(\"train_classes shape:\",train_classes.shape)\n",
    "print(\"test_classes shape:\",test_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DNN\n",
    "# Use Keras Backend Type\n",
    "train_set_d=train_set.astype(K.floatx())\n",
    "test_set_d=test_set.astype(K.floatx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
    "integer_encoded_train_classes =  train_classes.reshape(len( train_classes), 1)\n",
    "onehot_encoded_train_classes = onehot_encoder.fit_transform(integer_encoded_train_classes,1)\n",
    "integer_encoded_test_classes =  test_classes.reshape(len( test_classes),1)\n",
    "onehot_encoded_test_classes = onehot_encoder.fit_transform(integer_encoded_test_classes,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape Sets for Keras\n",
    "train_set_d=train_set.reshape(train_set_d.shape[0],1,train_set_d.shape[1])\n",
    "test_set_d=test_set.reshape(test_set_d.shape[0],1,test_set_d.shape[1])\n",
    "train_classes_d_hot=onehot_encoded_train_classes.reshape(onehot_encoded_train_classes.shape[0],1,\n",
    "                                                         onehot_encoded_train_classes.shape[1])\n",
    "test_classes_d_hot=onehot_encoded_test_classes.reshape(onehot_encoded_test_classes.shape[0],1,\n",
    "                                                       onehot_encoded_test_classes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set shape: (450, 1, 13)\n",
      "test_set shape: (450, 1, 13)\n",
      "train_classes shape: (450, 1, 6)\n",
      "test_classes shape: (150, 1, 6)\n"
     ]
    }
   ],
   "source": [
    "# Check Set Shapes\n",
    "print(\"train_set shape:\",train_set_d.shape)\n",
    "print(\"test_set shape:\",train_set_d.shape)\n",
    "print(\"train_classes shape:\",train_classes_d_hot.shape)\n",
    "print(\"test_classes shape:\",test_classes_d_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<center><iframe src=\"https://keras.io/getting-started/sequential-model-guide/\" width=\"800\" height=\"600\" frameborder=\"0\" marginheight=\"0\" marginwidth=\"0\">Loading...</iframe></center>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_web(\"https://keras.io/getting-started/sequential-model-guide/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(fc_layers=[4],\n",
    "                 activation='relu',\n",
    "                 optimizer='rmsprop'):\n",
    "    model = Sequential()\n",
    "\n",
    "    for i, size in enumerate(fc_layers):\n",
    "        # Input Layer - includes the input_shape\n",
    "        if i == 0:\n",
    "            model.add(Dense(size,\n",
    "                            activation=activation,\n",
    "                            input_shape=(train_set.shape[1],)))\n",
    "        else:\n",
    "            model.add(Dense(size,\n",
    "                            activation=activation))\n",
    "            \n",
    "    model.add(Dense(6,activation='softmax'))\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=create_model,\n",
    "                        epochs=50, \n",
    "                        batch_size=5,\n",
    "                        verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'fc_layers': [[12],[12,6],[6,6,6], [6]],\n",
    "              'activation':['relu','tanh'],\n",
    "              'optimizer':('rmsprop','adam'),\n",
    "              'epochs':[100, 150],\n",
    "              'batch_size':[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 816us/step - loss: 1.9290 - accuracy: 0.1889\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 811us/step - loss: 1.6570 - accuracy: 0.3083\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 679us/step - loss: 1.4392 - accuracy: 0.4083\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 575us/step - loss: 1.2607 - accuracy: 0.5583\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 558us/step - loss: 1.1075 - accuracy: 0.6472\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 643us/step - loss: 0.9813 - accuracy: 0.6861\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 557us/step - loss: 0.8774 - accuracy: 0.7389\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 610us/step - loss: 0.7892 - accuracy: 0.7528\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.7160 - accuracy: 0.7833\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 514us/step - loss: 0.6527 - accuracy: 0.7972\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.5966 - accuracy: 0.8167\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 615us/step - loss: 0.5476 - accuracy: 0.8306\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 672us/step - loss: 0.5047 - accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 639us/step - loss: 0.4644 - accuracy: 0.8778\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.4295 - accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.3978 - accuracy: 0.9000\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.3686 - accuracy: 0.9083\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.3407 - accuracy: 0.9167\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 634us/step - loss: 0.3167 - accuracy: 0.9250\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 626us/step - loss: 0.2935 - accuracy: 0.9278\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 533us/step - loss: 0.2735 - accuracy: 0.9389\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.2557 - accuracy: 0.9389\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 524us/step - loss: 0.2392 - accuracy: 0.9528\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.2246 - accuracy: 0.9611\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 656us/step - loss: 0.2109 - accuracy: 0.9611\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.1995 - accuracy: 0.9611\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 664us/step - loss: 0.1884 - accuracy: 0.9611\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 686us/step - loss: 0.1782 - accuracy: 0.9639\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.1694 - accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.1612 - accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 738us/step - loss: 0.1532 - accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 851us/step - loss: 0.1462 - accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 760us/step - loss: 0.1393 - accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 756us/step - loss: 0.1339 - accuracy: 0.9694\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 729us/step - loss: 0.1282 - accuracy: 0.9750\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.1238 - accuracy: 0.9778\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 736us/step - loss: 0.1191 - accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 768us/step - loss: 0.1145 - accuracy: 0.9778\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 751us/step - loss: 0.1101 - accuracy: 0.9806\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.1052 - accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 800us/step - loss: 0.1023 - accuracy: 0.9806\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 713us/step - loss: 0.0978 - accuracy: 0.9778\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 649us/step - loss: 0.0955 - accuracy: 0.9806\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 650us/step - loss: 0.0917 - accuracy: 0.9778\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.0890 - accuracy: 0.9778\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 709us/step - loss: 0.0858 - accuracy: 0.9806\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.0835 - accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 817us/step - loss: 0.0802 - accuracy: 0.9833\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 742us/step - loss: 0.0779 - accuracy: 0.9833\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 646us/step - loss: 0.0753 - accuracy: 0.9806\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 662us/step - loss: 0.0733 - accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.0714 - accuracy: 0.9833\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0686 - accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 506us/step - loss: 0.0677 - accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 506us/step - loss: 0.0661 - accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 496us/step - loss: 0.0639 - accuracy: 0.9833\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 495us/step - loss: 0.0628 - accuracy: 0.9861\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 501us/step - loss: 0.0606 - accuracy: 0.9861\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0590 - accuracy: 0.9861\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.0577 - accuracy: 0.9861\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.0562 - accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.0544 - accuracy: 0.9861\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 780us/step - loss: 0.0537 - accuracy: 0.9806\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 766us/step - loss: 0.0525 - accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 775us/step - loss: 0.0509 - accuracy: 0.9889\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 761us/step - loss: 0.0500 - accuracy: 0.9861\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 692us/step - loss: 0.0485 - accuracy: 0.9889\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.0480 - accuracy: 0.9861\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 553us/step - loss: 0.0465 - accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0462 - accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.0454 - accuracy: 0.9889\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.0442 - accuracy: 0.9889\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 628us/step - loss: 0.0431 - accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.0421 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 629us/step - loss: 0.0408 - accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.0416 - accuracy: 0.9889\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 751us/step - loss: 0.0400 - accuracy: 0.9917\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.0387 - accuracy: 0.9917\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.0382 - accuracy: 0.9917\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.0379 - accuracy: 0.9917\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 622us/step - loss: 0.0363 - accuracy: 0.9917\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 615us/step - loss: 0.0359 - accuracy: 0.9917\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.0362 - accuracy: 0.9917\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.0345 - accuracy: 0.9917\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0353 - accuracy: 0.9917\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 682us/step - loss: 0.0340 - accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.0343 - accuracy: 0.9917\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.0331 - accuracy: 0.9917\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 628us/step - loss: 0.0332 - accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.0319 - accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 658us/step - loss: 0.0319 - accuracy: 0.9917\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.0306 - accuracy: 0.9917\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 584us/step - loss: 0.0303 - accuracy: 0.9917\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 567us/step - loss: 0.0294 - accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0294 - accuracy: 0.9917\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 519us/step - loss: 0.0289 - accuracy: 0.9917\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.0282 - accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.0279 - accuracy: 0.9917\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0278 - accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.0269 - accuracy: 0.9917\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 861us/step - loss: 2.1180 - accuracy: 0.1139\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 805us/step - loss: 1.7787 - accuracy: 0.2111\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 684us/step - loss: 1.5501 - accuracy: 0.3306\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 1.3688 - accuracy: 0.4472\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 579us/step - loss: 1.2179 - accuracy: 0.6222\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 533us/step - loss: 1.0827 - accuracy: 0.6889\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 566us/step - loss: 0.9533 - accuracy: 0.7500\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.8323 - accuracy: 0.7833\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.7247 - accuracy: 0.8056\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.6271 - accuracy: 0.8417\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 632us/step - loss: 0.5427 - accuracy: 0.8528\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.4752 - accuracy: 0.8806\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 579us/step - loss: 0.4204 - accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 557us/step - loss: 0.3765 - accuracy: 0.9056\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 522us/step - loss: 0.3399 - accuracy: 0.9111\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 690us/step - loss: 0.3109 - accuracy: 0.9083\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 661us/step - loss: 0.2865 - accuracy: 0.9194\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.2652 - accuracy: 0.9222\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 562us/step - loss: 0.2466 - accuracy: 0.9306\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.2298 - accuracy: 0.9361\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.2149 - accuracy: 0.9417\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 562us/step - loss: 0.2016 - accuracy: 0.9417\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 514us/step - loss: 0.1895 - accuracy: 0.9472\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 544us/step - loss: 0.1790 - accuracy: 0.9528\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 615us/step - loss: 0.1688 - accuracy: 0.9639\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 711us/step - loss: 0.1599 - accuracy: 0.9639\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.1517 - accuracy: 0.9639\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 530us/step - loss: 0.1436 - accuracy: 0.9694\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 586us/step - loss: 0.1368 - accuracy: 0.9750\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 543us/step - loss: 0.1301 - accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.1238 - accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 548us/step - loss: 0.1181 - accuracy: 0.9722\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.1131 - accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.1082 - accuracy: 0.9778\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 579us/step - loss: 0.1041 - accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0992 - accuracy: 0.9806\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 655us/step - loss: 0.0955 - accuracy: 0.9778\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 686us/step - loss: 0.0908 - accuracy: 0.9750\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.0875 - accuracy: 0.9778\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 549us/step - loss: 0.0837 - accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0800 - accuracy: 0.9806\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.0760 - accuracy: 0.9861\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.0737 - accuracy: 0.9833\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.0706 - accuracy: 0.9861\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.0675 - accuracy: 0.9861\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 681us/step - loss: 0.0654 - accuracy: 0.9861\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.0628 - accuracy: 0.9889\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0601 - accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 539us/step - loss: 0.0579 - accuracy: 0.9889\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.0558 - accuracy: 0.9917\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.0536 - accuracy: 0.9917\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.0522 - accuracy: 0.9917\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.0499 - accuracy: 0.9917\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 660us/step - loss: 0.0479 - accuracy: 0.9917\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 715us/step - loss: 0.0469 - accuracy: 0.9944\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0446 - accuracy: 0.9944\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 639us/step - loss: 0.0433 - accuracy: 0.9944\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.0417 - accuracy: 0.9944\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 660us/step - loss: 0.0402 - accuracy: 0.9944\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.0392 - accuracy: 0.9944\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 588us/step - loss: 0.0372 - accuracy: 0.9972\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0362 - accuracy: 0.9972\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.0352 - accuracy: 0.9972\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.0338 - accuracy: 0.9972\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0329 - accuracy: 0.9972\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.0321 - accuracy: 0.9972\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0307 - accuracy: 0.9972\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 645us/step - loss: 0.0299 - accuracy: 0.9972\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.0289 - accuracy: 0.9972\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 668us/step - loss: 0.0280 - accuracy: 0.9972\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.0271 - accuracy: 0.9972\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.0262 - accuracy: 0.9972\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 563us/step - loss: 0.0254 - accuracy: 0.9972\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.0248 - accuracy: 0.9972\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0238 - accuracy: 0.9972\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.0232 - accuracy: 0.9972\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 725us/step - loss: 0.0224 - accuracy: 0.9972\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.0222 - accuracy: 0.9972\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.0212 - accuracy: 0.9972\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 572us/step - loss: 0.0207 - accuracy: 0.9972\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0197 - accuracy: 0.9972\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.0197 - accuracy: 0.9972\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 630us/step - loss: 0.0190 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 557us/step - loss: 0.0177 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 680us/step - loss: 0.0185 - accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 625us/step - loss: 0.0175 - accuracy: 0.9972\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.0170 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 532us/step - loss: 0.0167 - accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.0163 - accuracy: 0.9972\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 517us/step - loss: 0.0157 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 646us/step - loss: 0.0149 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 689us/step - loss: 0.0145 - accuracy: 0.9972\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.0138 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.0137 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 539us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 642us/step - loss: 0.0130 - accuracy: 0.9972\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 874us/step - loss: 0.0124 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 767us/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 647us/step - loss: 1.9572 - accuracy: 0.1417\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 513us/step - loss: 1.7180 - accuracy: 0.2167\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 1.5503 - accuracy: 0.2917\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 510us/step - loss: 1.4167 - accuracy: 0.3556\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 1.2997 - accuracy: 0.4556\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 1.1904 - accuracy: 0.5528\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 641us/step - loss: 1.0854 - accuracy: 0.6389\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 625us/step - loss: 0.9867 - accuracy: 0.7028\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.8969 - accuracy: 0.7389\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 683us/step - loss: 0.8113 - accuracy: 0.7639\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 658us/step - loss: 0.7356 - accuracy: 0.7889\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.6677 - accuracy: 0.8111\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 711us/step - loss: 0.6060 - accuracy: 0.8306\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 666us/step - loss: 0.5515 - accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.5029 - accuracy: 0.8639\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.4599 - accuracy: 0.8778\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.4225 - accuracy: 0.8972\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 643us/step - loss: 0.3892 - accuracy: 0.9028\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 626us/step - loss: 0.3597 - accuracy: 0.9222\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 672us/step - loss: 0.3318 - accuracy: 0.9333\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 694us/step - loss: 0.3057 - accuracy: 0.9361\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.2821 - accuracy: 0.9500\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 782us/step - loss: 0.2615 - accuracy: 0.9444\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 626us/step - loss: 0.2435 - accuracy: 0.9556\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 534us/step - loss: 0.2265 - accuracy: 0.9583\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 516us/step - loss: 0.2121 - accuracy: 0.9611\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.1987 - accuracy: 0.9583\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.1866 - accuracy: 0.9611\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 656us/step - loss: 0.1753 - accuracy: 0.9667\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.1659 - accuracy: 0.9722\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 535us/step - loss: 0.1570 - accuracy: 0.9722\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.1487 - accuracy: 0.9778\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 542us/step - loss: 0.1407 - accuracy: 0.9806\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.1337 - accuracy: 0.9778\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 579us/step - loss: 0.1278 - accuracy: 0.9806\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.1220 - accuracy: 0.9833\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 566us/step - loss: 0.1171 - accuracy: 0.9861\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.1121 - accuracy: 0.9833\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.1080 - accuracy: 0.9861\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.1029 - accuracy: 0.9861\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 575us/step - loss: 0.1000 - accuracy: 0.9833\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 532us/step - loss: 0.0961 - accuracy: 0.9889\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.0932 - accuracy: 0.9889\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 553us/step - loss: 0.0898 - accuracy: 0.9889\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0866 - accuracy: 0.9889\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.0843 - accuracy: 0.9889\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0819 - accuracy: 0.9889\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 674us/step - loss: 0.0793 - accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.0768 - accuracy: 0.9889\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.0752 - accuracy: 0.9889\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0729 - accuracy: 0.9889\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.0711 - accuracy: 0.9889\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 542us/step - loss: 0.0693 - accuracy: 0.9889\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 519us/step - loss: 0.0679 - accuracy: 0.9889\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.0661 - accuracy: 0.9889\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 534us/step - loss: 0.0637 - accuracy: 0.9889\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 577us/step - loss: 0.0634 - accuracy: 0.9889\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0609 - accuracy: 0.9889\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.0602 - accuracy: 0.9889\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 532us/step - loss: 0.0589 - accuracy: 0.9889\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 521us/step - loss: 0.0570 - accuracy: 0.9889\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 518us/step - loss: 0.0554 - accuracy: 0.9889\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 516us/step - loss: 0.0544 - accuracy: 0.9889\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 514us/step - loss: 0.0530 - accuracy: 0.9889\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.0512 - accuracy: 0.9889\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 508us/step - loss: 0.0514 - accuracy: 0.9889\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 537us/step - loss: 0.0499 - accuracy: 0.9889\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 624us/step - loss: 0.0487 - accuracy: 0.9889\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 642us/step - loss: 0.0476 - accuracy: 0.9889\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.0467 - accuracy: 0.9889\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0459 - accuracy: 0.9889\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 522us/step - loss: 0.0446 - accuracy: 0.9889\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 525us/step - loss: 0.0444 - accuracy: 0.9889\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0434 - accuracy: 0.9889\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 552us/step - loss: 0.0417 - accuracy: 0.9889\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 505us/step - loss: 0.0422 - accuracy: 0.9889\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0407 - accuracy: 0.9889\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 524us/step - loss: 0.0410 - accuracy: 0.9889\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.0397 - accuracy: 0.9889\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 535us/step - loss: 0.0387 - accuracy: 0.9889\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 521us/step - loss: 0.0373 - accuracy: 0.9889\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0367 - accuracy: 0.9889\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.0362 - accuracy: 0.9889\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.0352 - accuracy: 0.9889\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 708us/step - loss: 0.0359 - accuracy: 0.9889\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 630us/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 527us/step - loss: 0.0338 - accuracy: 0.9889\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 551us/step - loss: 0.0336 - accuracy: 0.9889\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 510us/step - loss: 0.0325 - accuracy: 0.9889\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0321 - accuracy: 0.9889\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 512us/step - loss: 0.0306 - accuracy: 0.9889\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 510us/step - loss: 0.0309 - accuracy: 0.9889\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.0298 - accuracy: 0.9889\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 528us/step - loss: 0.0288 - accuracy: 0.9889\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 564us/step - loss: 0.0291 - accuracy: 0.9889\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0283 - accuracy: 0.9889\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 531us/step - loss: 0.0272 - accuracy: 0.9889\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0263 - accuracy: 0.9889\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 541us/step - loss: 0.0267 - accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0263 - accuracy: 0.9889\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 657us/step - loss: 1.7052 - accuracy: 0.2583\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 540us/step - loss: 1.5102 - accuracy: 0.3444\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 522us/step - loss: 1.3553 - accuracy: 0.4333\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 514us/step - loss: 1.2272 - accuracy: 0.5139\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 602us/step - loss: 1.1132 - accuracy: 0.5861\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 567us/step - loss: 1.0093 - accuracy: 0.6556\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.9163 - accuracy: 0.6972\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 517us/step - loss: 0.8334 - accuracy: 0.7667\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.7585 - accuracy: 0.7889\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 584us/step - loss: 0.6894 - accuracy: 0.8444\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.6286 - accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.5718 - accuracy: 0.8778\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 556us/step - loss: 0.5225 - accuracy: 0.8861\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.4784 - accuracy: 0.8972\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 510us/step - loss: 0.4403 - accuracy: 0.9028\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 572us/step - loss: 0.4053 - accuracy: 0.9111\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 556us/step - loss: 0.3745 - accuracy: 0.9167\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 579us/step - loss: 0.3457 - accuracy: 0.9278\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 535us/step - loss: 0.3205 - accuracy: 0.9333\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.2973 - accuracy: 0.9361\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 651us/step - loss: 0.2752 - accuracy: 0.9417\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.2561 - accuracy: 0.9444\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 527us/step - loss: 0.2396 - accuracy: 0.9528\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 577us/step - loss: 0.2244 - accuracy: 0.9528\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 527us/step - loss: 0.2101 - accuracy: 0.9556\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.1983 - accuracy: 0.9639\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 536us/step - loss: 0.1872 - accuracy: 0.9639\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.1784 - accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.1696 - accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.1607 - accuracy: 0.9722\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.1538 - accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 521us/step - loss: 0.1470 - accuracy: 0.9694\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.1405 - accuracy: 0.9722\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 523us/step - loss: 0.1362 - accuracy: 0.9667\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.1305 - accuracy: 0.9722\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.1260 - accuracy: 0.9722\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 525us/step - loss: 0.1210 - accuracy: 0.9667\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.1176 - accuracy: 0.9694\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 563us/step - loss: 0.1136 - accuracy: 0.9694\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 610us/step - loss: 0.1101 - accuracy: 0.9694\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 547us/step - loss: 0.1069 - accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.1037 - accuracy: 0.9750\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 525us/step - loss: 0.1010 - accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.0975 - accuracy: 0.9750\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 509us/step - loss: 0.0944 - accuracy: 0.9750\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 532us/step - loss: 0.0923 - accuracy: 0.9750\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 515us/step - loss: 0.0898 - accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.0874 - accuracy: 0.9806\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 631us/step - loss: 0.0852 - accuracy: 0.9806\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 550us/step - loss: 0.0829 - accuracy: 0.9861\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0812 - accuracy: 0.9833\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 539us/step - loss: 0.0787 - accuracy: 0.9806\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.0768 - accuracy: 0.9833\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 508us/step - loss: 0.0747 - accuracy: 0.9861\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.0732 - accuracy: 0.9833\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 557us/step - loss: 0.0712 - accuracy: 0.9861\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0700 - accuracy: 0.9833\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 532us/step - loss: 0.0681 - accuracy: 0.9861\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.0672 - accuracy: 0.9889\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 545us/step - loss: 0.0655 - accuracy: 0.9917\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 551us/step - loss: 0.0639 - accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.0626 - accuracy: 0.9917\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.0608 - accuracy: 0.9889\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.0597 - accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.0586 - accuracy: 0.9917\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 524us/step - loss: 0.0578 - accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 517us/step - loss: 0.0561 - accuracy: 0.9917\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.0547 - accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 523us/step - loss: 0.0531 - accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.0526 - accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 547us/step - loss: 0.0521 - accuracy: 0.9917\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0509 - accuracy: 0.9917\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.0498 - accuracy: 0.9917\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 693us/step - loss: 0.0492 - accuracy: 0.9917\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0477 - accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 522us/step - loss: 0.0468 - accuracy: 0.9917\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 558us/step - loss: 0.0463 - accuracy: 0.9917\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.0450 - accuracy: 0.9917\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.0447 - accuracy: 0.9917\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 555us/step - loss: 0.0440 - accuracy: 0.9917\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 530us/step - loss: 0.0423 - accuracy: 0.9917\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.0420 - accuracy: 0.9917\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 535us/step - loss: 0.0413 - accuracy: 0.9917\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0404 - accuracy: 0.9917\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.0403 - accuracy: 0.9917\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0391 - accuracy: 0.9917\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.0382 - accuracy: 0.9917\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 517us/step - loss: 0.0377 - accuracy: 0.9917\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.0369 - accuracy: 0.9917\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 586us/step - loss: 0.0362 - accuracy: 0.9917\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0356 - accuracy: 0.9917\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.0351 - accuracy: 0.9917\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 564us/step - loss: 0.0342 - accuracy: 0.9917\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0339 - accuracy: 0.9917\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.0330 - accuracy: 0.9917\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 551us/step - loss: 0.0325 - accuracy: 0.9917\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.0321 - accuracy: 0.9917\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.0312 - accuracy: 0.9917\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.0306 - accuracy: 0.9917\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.0303 - accuracy: 0.9917\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 666us/step - loss: 1.8565 - accuracy: 0.1556\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 552us/step - loss: 1.6227 - accuracy: 0.3583\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 564us/step - loss: 1.4340 - accuracy: 0.4861\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 516us/step - loss: 1.2703 - accuracy: 0.5278\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 562us/step - loss: 1.1285 - accuracy: 0.5944\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 529us/step - loss: 0.9984 - accuracy: 0.6639\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 558us/step - loss: 0.8814 - accuracy: 0.7306\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.7817 - accuracy: 0.7917\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.6913 - accuracy: 0.8250\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 525us/step - loss: 0.6141 - accuracy: 0.8639\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 641us/step - loss: 0.5467 - accuracy: 0.8833\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 772us/step - loss: 0.4902 - accuracy: 0.9139\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 812us/step - loss: 0.4425 - accuracy: 0.9139\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 729us/step - loss: 0.4023 - accuracy: 0.9250\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.3687 - accuracy: 0.9361\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.3390 - accuracy: 0.9417\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 529us/step - loss: 0.3139 - accuracy: 0.9417\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.2911 - accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 517us/step - loss: 0.2720 - accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 548us/step - loss: 0.2536 - accuracy: 0.9500\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 534us/step - loss: 0.2378 - accuracy: 0.9500\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.2254 - accuracy: 0.9583\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.9583\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 792us/step - loss: 0.2022 - accuracy: 0.9583\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 773us/step - loss: 0.1917 - accuracy: 0.9583\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.1822 - accuracy: 0.9639\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.1741 - accuracy: 0.9611\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 530us/step - loss: 0.1665 - accuracy: 0.9639\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 584us/step - loss: 0.1592 - accuracy: 0.9639\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 529us/step - loss: 0.1523 - accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 548us/step - loss: 0.1461 - accuracy: 0.9667\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 590us/step - loss: 0.1403 - accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.1355 - accuracy: 0.9694\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.1301 - accuracy: 0.9667\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 514us/step - loss: 0.1257 - accuracy: 0.9694\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 572us/step - loss: 0.1211 - accuracy: 0.9667\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 552us/step - loss: 0.1165 - accuracy: 0.9694\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 572us/step - loss: 0.1130 - accuracy: 0.9722\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 524us/step - loss: 0.1099 - accuracy: 0.9722\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.1053 - accuracy: 0.9722\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 531us/step - loss: 0.1026 - accuracy: 0.9722\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.0993 - accuracy: 0.9722\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.0963 - accuracy: 0.9722\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 586us/step - loss: 0.0933 - accuracy: 0.9750\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 590us/step - loss: 0.0913 - accuracy: 0.9722\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 584us/step - loss: 0.0878 - accuracy: 0.9722\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 530us/step - loss: 0.0853 - accuracy: 0.9750\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0829 - accuracy: 0.9778\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.0808 - accuracy: 0.9750\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0788 - accuracy: 0.9778\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.0761 - accuracy: 0.9778\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.0742 - accuracy: 0.9778\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.0721 - accuracy: 0.9806\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.0696 - accuracy: 0.9806\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.0674 - accuracy: 0.9861\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.0667 - accuracy: 0.9806\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.0650 - accuracy: 0.9750\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 550us/step - loss: 0.0631 - accuracy: 0.9806\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.0621 - accuracy: 0.9806\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 525us/step - loss: 0.0601 - accuracy: 0.9861\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.0586 - accuracy: 0.9861\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.0583 - accuracy: 0.9806\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 590us/step - loss: 0.0556 - accuracy: 0.9861\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.0551 - accuracy: 0.9861\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 563us/step - loss: 0.0534 - accuracy: 0.9889\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 653us/step - loss: 0.0528 - accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.0508 - accuracy: 0.9917\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 638us/step - loss: 0.0495 - accuracy: 0.9889\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 562us/step - loss: 0.0484 - accuracy: 0.9889\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0476 - accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 530us/step - loss: 0.0469 - accuracy: 0.9917\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.0460 - accuracy: 0.9917\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0444 - accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.0435 - accuracy: 0.9944\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0428 - accuracy: 0.9944\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.0419 - accuracy: 0.9944\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 552us/step - loss: 0.0411 - accuracy: 0.9944\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 606us/step - loss: 0.0405 - accuracy: 0.9944\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.0401 - accuracy: 0.9944\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.0387 - accuracy: 0.9944\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 543us/step - loss: 0.0378 - accuracy: 0.9944\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.0370 - accuracy: 0.9944\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 584us/step - loss: 0.0364 - accuracy: 0.9944\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 541us/step - loss: 0.0357 - accuracy: 0.9944\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0359 - accuracy: 0.9944\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 575us/step - loss: 0.0349 - accuracy: 0.9944\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.0339 - accuracy: 0.9944\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 543us/step - loss: 0.0334 - accuracy: 0.9944\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 531us/step - loss: 0.0331 - accuracy: 0.9944\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.0325 - accuracy: 0.9944\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.0322 - accuracy: 0.9944\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 621us/step - loss: 0.0317 - accuracy: 0.9944\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0301 - accuracy: 0.9944\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.0304 - accuracy: 0.9944\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0297 - accuracy: 0.9944\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0297 - accuracy: 0.9944\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 535us/step - loss: 0.0294 - accuracy: 0.9944\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 597us/step - loss: 0.0281 - accuracy: 0.9944\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 528us/step - loss: 0.0278 - accuracy: 0.9944\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.0270 - accuracy: 0.9944\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 594us/step - loss: 1.8689 - accuracy: 0.2056\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 565us/step - loss: 1.6340 - accuracy: 0.3361\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 1.4474 - accuracy: 0.4444\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 1.2956 - accuracy: 0.5250\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 526us/step - loss: 1.1652 - accuracy: 0.5667\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 617us/step - loss: 1.0491 - accuracy: 0.6306\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 537us/step - loss: 0.9454 - accuracy: 0.6944\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 565us/step - loss: 0.8520 - accuracy: 0.7389\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.7686 - accuracy: 0.7722\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.6944 - accuracy: 0.8167\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 565us/step - loss: 0.6325 - accuracy: 0.8361\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.5760 - accuracy: 0.8472\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 560us/step - loss: 0.5274 - accuracy: 0.8667\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.4833 - accuracy: 0.8833\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 562us/step - loss: 0.4446 - accuracy: 0.8889\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 586us/step - loss: 0.4104 - accuracy: 0.8972\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.3787 - accuracy: 0.9056\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.3499 - accuracy: 0.9194\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.3248 - accuracy: 0.9250\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 612us/step - loss: 0.3036 - accuracy: 0.9250\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 567us/step - loss: 0.2832 - accuracy: 0.9333\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.2650 - accuracy: 0.9389\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.2492 - accuracy: 0.9528\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.2351 - accuracy: 0.9556\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.2219 - accuracy: 0.9556\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.2094 - accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.1990 - accuracy: 0.9667\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.1891 - accuracy: 0.9667\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 619us/step - loss: 0.1807 - accuracy: 0.9667\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 538us/step - loss: 0.1716 - accuracy: 0.9667\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.1640 - accuracy: 0.9694\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.1570 - accuracy: 0.9694\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.1517 - accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 564us/step - loss: 0.1450 - accuracy: 0.9722\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 607us/step - loss: 0.1390 - accuracy: 0.9694\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 591us/step - loss: 0.1337 - accuracy: 0.9750\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 586us/step - loss: 0.1288 - accuracy: 0.9750\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 552us/step - loss: 0.1244 - accuracy: 0.9806\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 585us/step - loss: 0.1196 - accuracy: 0.9778\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.1158 - accuracy: 0.9806\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 0s 580us/step - loss: 0.1116 - accuracy: 0.9833\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.1082 - accuracy: 0.9806\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.1043 - accuracy: 0.9861\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 589us/step - loss: 0.1009 - accuracy: 0.9861\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0972 - accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 620us/step - loss: 0.0944 - accuracy: 0.9861\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 547us/step - loss: 0.0912 - accuracy: 0.9889\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.0887 - accuracy: 0.9861\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.0859 - accuracy: 0.9861\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.0837 - accuracy: 0.9833\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.0803 - accuracy: 0.9889\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0785 - accuracy: 0.9889\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.0764 - accuracy: 0.9889\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 542us/step - loss: 0.0741 - accuracy: 0.9889\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0722 - accuracy: 0.9889\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 577us/step - loss: 0.0701 - accuracy: 0.9917\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 563us/step - loss: 0.0677 - accuracy: 0.9917\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 654us/step - loss: 0.0664 - accuracy: 0.9917\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.0641 - accuracy: 0.9917\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 541us/step - loss: 0.0625 - accuracy: 0.9917\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 599us/step - loss: 0.0604 - accuracy: 0.9917\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.0595 - accuracy: 0.9917\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.0577 - accuracy: 0.9917\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0563 - accuracy: 0.9917\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 543us/step - loss: 0.0547 - accuracy: 0.9917\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0531 - accuracy: 0.9917\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 588us/step - loss: 0.0519 - accuracy: 0.9917\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 608us/step - loss: 0.0509 - accuracy: 0.9917\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.0492 - accuracy: 0.9917\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 543us/step - loss: 0.0480 - accuracy: 0.9917\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 550us/step - loss: 0.0468 - accuracy: 0.9917\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 602us/step - loss: 0.0453 - accuracy: 0.9917\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 622us/step - loss: 0.0441 - accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0432 - accuracy: 0.9944\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 613us/step - loss: 0.0426 - accuracy: 0.9917\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 646us/step - loss: 0.0413 - accuracy: 0.9944\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 641us/step - loss: 0.0398 - accuracy: 0.9944\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 550us/step - loss: 0.0392 - accuracy: 0.9944\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.0378 - accuracy: 0.9917\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0372 - accuracy: 0.9944\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 548us/step - loss: 0.0364 - accuracy: 0.9944\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 592us/step - loss: 0.0351 - accuracy: 0.9972\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 629us/step - loss: 0.0343 - accuracy: 0.9972\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 551us/step - loss: 0.0337 - accuracy: 0.9972\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0330 - accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.0321 - accuracy: 0.9972\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 546us/step - loss: 0.0311 - accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0303 - accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.0297 - accuracy: 0.9972\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 603us/step - loss: 0.0289 - accuracy: 0.9972\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.0283 - accuracy: 0.9972\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 630us/step - loss: 0.0276 - accuracy: 0.9972\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 564us/step - loss: 0.0269 - accuracy: 0.9972\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0262 - accuracy: 0.9972\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.0255 - accuracy: 0.9972\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.0250 - accuracy: 0.9972\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0243 - accuracy: 0.9972\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.0241 - accuracy: 0.9972\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 573us/step - loss: 0.0233 - accuracy: 0.9972\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 642us/step - loss: 0.0231 - accuracy: 0.9972\n",
      "Epoch 1/100\n",
      "72/72 [==============================] - 0s 745us/step - loss: 1.8476 - accuracy: 0.2028\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 0s 670us/step - loss: 1.5834 - accuracy: 0.3417\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 0s 637us/step - loss: 1.3830 - accuracy: 0.4833\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 1.2267 - accuracy: 0.5583\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 1.1028 - accuracy: 0.5944\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 0s 643us/step - loss: 0.9933 - accuracy: 0.6750\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 0s 888us/step - loss: 0.8919 - accuracy: 0.7250\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 0s 687us/step - loss: 0.8009 - accuracy: 0.7639\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 0s 537us/step - loss: 0.7172 - accuracy: 0.8222\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 0s 605us/step - loss: 0.6445 - accuracy: 0.8528\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 0s 683us/step - loss: 0.5810 - accuracy: 0.8722\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 0s 683us/step - loss: 0.5250 - accuracy: 0.8889\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 0s 669us/step - loss: 0.4779 - accuracy: 0.9000\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 0s 636us/step - loss: 0.4363 - accuracy: 0.9167\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 0s 675us/step - loss: 0.4008 - accuracy: 0.9361\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.3696 - accuracy: 0.9333\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 0s 757us/step - loss: 0.3416 - accuracy: 0.9333\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.3179 - accuracy: 0.9500\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 0s 670us/step - loss: 0.2965 - accuracy: 0.9500\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.2774 - accuracy: 0.9583\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.2599 - accuracy: 0.9528\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.2447 - accuracy: 0.9556\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 0s 954us/step - loss: 0.2305 - accuracy: 0.9611\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 0s 718us/step - loss: 0.2179 - accuracy: 0.9667\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 0s 722us/step - loss: 0.2067 - accuracy: 0.9667\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 0s 839us/step - loss: 0.1961 - accuracy: 0.9667\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 0s 891us/step - loss: 0.1869 - accuracy: 0.9694\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 0s 789us/step - loss: 0.1784 - accuracy: 0.9722\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 0s 684us/step - loss: 0.1708 - accuracy: 0.9694\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 0s 601us/step - loss: 0.1633 - accuracy: 0.9750\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 0s 561us/step - loss: 0.1561 - accuracy: 0.9750\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 0s 558us/step - loss: 0.1503 - accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 0s 628us/step - loss: 0.1451 - accuracy: 0.9750\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.1391 - accuracy: 0.9806\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.1332 - accuracy: 0.9778\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.1282 - accuracy: 0.9750\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 0s 646us/step - loss: 0.1243 - accuracy: 0.9806\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 0s 671us/step - loss: 0.1199 - accuracy: 0.9778\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 0s 684us/step - loss: 0.1155 - accuracy: 0.9806\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 0s 747us/step - loss: 0.1114 - accuracy: 0.9833\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 691us/step - loss: 0.1075 - accuracy: 0.9806\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 0s 641us/step - loss: 0.1050 - accuracy: 0.9833\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 0s 654us/step - loss: 0.1013 - accuracy: 0.9861\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0977 - accuracy: 0.9889\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 0s 558us/step - loss: 0.0955 - accuracy: 0.9917\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 0s 614us/step - loss: 0.0922 - accuracy: 0.9889\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 0s 567us/step - loss: 0.0899 - accuracy: 0.9917\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.0869 - accuracy: 0.9889\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.0847 - accuracy: 0.9917\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 0s 537us/step - loss: 0.0820 - accuracy: 0.9889\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 0s 559us/step - loss: 0.0796 - accuracy: 0.9917\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.0774 - accuracy: 0.9917\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 0s 542us/step - loss: 0.0756 - accuracy: 0.9944\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0735 - accuracy: 0.9917\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.0713 - accuracy: 0.9944\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 0s 625us/step - loss: 0.0694 - accuracy: 0.9944\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.0679 - accuracy: 0.9944\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 0s 611us/step - loss: 0.0664 - accuracy: 0.9944\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 0s 571us/step - loss: 0.0644 - accuracy: 0.9944\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 0s 627us/step - loss: 0.0631 - accuracy: 0.9944\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.0612 - accuracy: 0.9944\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 0s 633us/step - loss: 0.0602 - accuracy: 0.9944\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 0s 647us/step - loss: 0.0589 - accuracy: 0.9944\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0573 - accuracy: 0.9944\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 0s 805us/step - loss: 0.0555 - accuracy: 0.9944\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.0542 - accuracy: 0.9944\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 0s 593us/step - loss: 0.0532 - accuracy: 0.9944\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.0520 - accuracy: 0.9944\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 0s 685us/step - loss: 0.0504 - accuracy: 0.9944\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 0s 730us/step - loss: 0.0497 - accuracy: 0.9944\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 0s 676us/step - loss: 0.0481 - accuracy: 0.9944\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 0s 583us/step - loss: 0.0469 - accuracy: 0.9944\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 0s 590us/step - loss: 0.0460 - accuracy: 0.9944\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.0448 - accuracy: 0.9944\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 0s 604us/step - loss: 0.0442 - accuracy: 0.9944\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 0s 598us/step - loss: 0.0433 - accuracy: 0.9944\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 0s 594us/step - loss: 0.0420 - accuracy: 0.9944\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 0s 536us/step - loss: 0.0412 - accuracy: 0.9944\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 0s 569us/step - loss: 0.0399 - accuracy: 0.9944\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 0s 616us/step - loss: 0.0395 - accuracy: 0.9972\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 0s 566us/step - loss: 0.0384 - accuracy: 0.9972\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.0374 - accuracy: 0.9972\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0366 - accuracy: 0.9972\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 0s 576us/step - loss: 0.0359 - accuracy: 0.9972\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 0s 618us/step - loss: 0.0352 - accuracy: 0.9972\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 0s 640us/step - loss: 0.0343 - accuracy: 0.9972\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 0s 560us/step - loss: 0.0334 - accuracy: 0.9972\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 0s 565us/step - loss: 0.0327 - accuracy: 0.9972\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 0s 589us/step - loss: 0.0320 - accuracy: 0.9972\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 0s 542us/step - loss: 0.0308 - accuracy: 0.9972\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 0s 659us/step - loss: 0.0303 - accuracy: 0.9972\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 0s 600us/step - loss: 0.0299 - accuracy: 0.9972\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 0s 581us/step - loss: 0.0289 - accuracy: 0.9972\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 0s 595us/step - loss: 0.0284 - accuracy: 0.9972\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 0s 587us/step - loss: 0.0275 - accuracy: 0.9972\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 0s 574us/step - loss: 0.0271 - accuracy: 0.9972\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 0s 578us/step - loss: 0.0265 - accuracy: 0.9972\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 0s 599us/step - loss: 0.0261 - accuracy: 0.9972\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 0s 547us/step - loss: 0.0252 - accuracy: 0.9972\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 0s 570us/step - loss: 0.0249 - accuracy: 0.9972\n",
      "Epoch 1/100\n",
      " 1/72 [..............................] - ETA: 0s - loss: 1.5588 - accuracy: 0.6000"
     ]
    }
   ],
   "source": [
    "grid = GridSearchCV(model,\n",
    "                    param_grid=param_grid,\n",
    "                    return_train_score=True,\n",
    "                    cv=5)\n",
    "\n",
    "categorical_encoded_train_classes=to_categorical(integer_encoded_train_classes)\n",
    "grid_results = grid.fit(train_set,onehot_encoded_train_classes, verbose=1)\n",
    "\n",
    "print('Parameters of the best model: ')\n",
    "print(grid_results.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_results.best_score_, grid_results.best_params_))\n",
    "means = grid_results.cv_results_['mean_test_score']\n",
    "stds = grid_results.cv_results_['std_test_score']\n",
    "params = grid_results.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=create_model(fc_layers=[12],activation='relu', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning Parameters\n",
    "batch_size = 5 # Number of samples per gradient update.\n",
    "epochs = 150    # An epoch is an iteration over the entire x and y data provided.\n",
    "\n",
    "# Train Model\n",
    "hist = best_model.fit(train_set, onehot_encoded_train_classes, verbose=1, \n",
    "                    batch_size=batch_size, epochs=epochs, validation_data=(test_set,onehot_encoded_test_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    plt.figure(1)\n",
    "    for l in loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    plt.figure(2)\n",
    "    for l in acc_list:\n",
    "        plt.plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        plt.plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = best_model.predict(test_set)\n",
    "predictions_round=predictions.round().astype('int')\n",
    "predictions_int=np.argmax(predictions_round,axis=1)\n",
    "predictions_labels=labelencoder.inverse_transform(np.ravel(predictions_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  [0.96 1.   1.   0.96 0.92 0.92]\n",
      "Precision:  [1.         0.96153846 1.         0.96       0.92       0.92      ]\n",
      "F1-Score:  [0.97959184 0.98039216 1.         0.96       0.92       0.92      ]\n",
      "Accuracy: 0.96  , 144\n",
      "Number of samples: 150\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        25\n",
      "           1       0.96      1.00      0.98        25\n",
      "           2       1.00      1.00      1.00        25\n",
      "           3       0.96      0.96      0.96        25\n",
      "           4       0.92      0.92      0.92        25\n",
      "           5       0.92      0.92      0.92        25\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       150\n",
      "   macro avg       0.96      0.96      0.96       150\n",
      "weighted avg       0.96      0.96      0.96       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Recall - the ability of the classifier to find all the positive samples\n",
    "print(\"Recall: \", recall_score(test_classes, predictions_int,average=None))\n",
    "\n",
    "# Precision - The precision is intuitively the ability of the classifier not to \n",
    "#label as positive a sample that is negative\n",
    "print(\"Precision: \", precision_score(test_classes, predictions_int,average=None))\n",
    "\n",
    "# F1-Score - The F1 score can be interpreted as a weighted average of the precision \n",
    "#and recall\n",
    "print(\"F1-Score: \", f1_score(test_classes, predictions_int, average=None))\n",
    "\n",
    "# Accuracy - the number of correctly classified samples\n",
    "print(\"Accuracy: %.2f  ,\" % accuracy_score(test_classes, predictions_int,normalize=True), accuracy_score(test_classes, predictions_int,normalize=False) )\n",
    "print(\"Number of samples:\",test_classes.shape[0])\n",
    "\n",
    "print(classification_report(test_classes, predictions_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_classes, predictions_int)\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to Plot Confusion Matrix\n",
    "# http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    \"\"\"\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(16,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labelencoder.classes_,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find wrong predicted samples indexes\n",
    "wrong_predictions = [i for i, (e1, e2) in enumerate(zip(test_classes, predictions_int)) if e1 != e2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['oboe' 'flute' 'sax' 'trumpet' 'trumpet' 'trumpet']\n",
      "['sax' 'cello' 'flute' 'viola' 'sax' 'viola']\n",
      "['./audio/london_phill_dataset_multi/oboe/oboe_Ds6_05_fortissimo_normal.mp3'\n",
      " './audio/london_phill_dataset_multi/flute/flute_Gs5_025_forte_normal.mp3'\n",
      " './audio/london_phill_dataset_multi/sax/saxophone_A3_15_fortissimo_normal.mp3'\n",
      " './audio/london_phill_dataset_multi/trumpet/trumpet_A3_05_pianissimo_normal.mp3'\n",
      " './audio/london_phill_dataset_multi/trumpet/trumpet_A3_05_forte_normal.mp3'\n",
      " './audio/london_phill_dataset_multi/trumpet/trumpet_Cs4_15_pianissimo_normal.mp3']\n"
     ]
    }
   ],
   "source": [
    "# Find wrong predicted audio files\n",
    "print(np.array(labels)[test_index[wrong_predictions]])\n",
    "print(predictions_labels[wrong_predictions].T)\n",
    "print(np.array(files)[test_index[wrong_predictions]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_443 (Dense)            (None, 12)                168       \n",
      "_________________________________________________________________\n",
      "dense_444 (Dense)            (None, 6)                 78        \n",
      "=================================================================\n",
      "Total params: 246\n",
      "Trainable params: 246\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
